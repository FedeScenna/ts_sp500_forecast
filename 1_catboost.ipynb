{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a42081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skforecast.sarimax import Sarimax\n",
    "from tqdm import tqdm, trange\n",
    "from constants import end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78064813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>bb_low</th>\n",
       "      <th>bb_mid</th>\n",
       "      <th>bb_high</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>43.559391</td>\n",
       "      <td>55.906011</td>\n",
       "      <td>3.757332</td>\n",
       "      <td>3.781197</td>\n",
       "      <td>3.805061</td>\n",
       "      <td>0.548844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>26.827240</td>\n",
       "      <td>58.487161</td>\n",
       "      <td>3.274114</td>\n",
       "      <td>3.315296</td>\n",
       "      <td>3.356479</td>\n",
       "      <td>0.836831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>43.078159</td>\n",
       "      <td>53.851836</td>\n",
       "      <td>3.756310</td>\n",
       "      <td>3.777267</td>\n",
       "      <td>3.798224</td>\n",
       "      <td>0.661857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>ABT</td>\n",
       "      <td>33.307190</td>\n",
       "      <td>50.624336</td>\n",
       "      <td>3.504776</td>\n",
       "      <td>3.523770</td>\n",
       "      <td>3.542764</td>\n",
       "      <td>0.568612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>ACGL</td>\n",
       "      <td>27.224224</td>\n",
       "      <td>59.555791</td>\n",
       "      <td>3.323679</td>\n",
       "      <td>3.345575</td>\n",
       "      <td>3.367472</td>\n",
       "      <td>0.645114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker      close        rsi    bb_low    bb_mid   bb_high  \\\n",
       "0  2017-01-03      A  43.559391  55.906011  3.757332  3.781197  3.805061   \n",
       "1  2017-01-03   AAPL  26.827240  58.487161  3.274114  3.315296  3.356479   \n",
       "2  2017-01-03   ABBV  43.078159  53.851836  3.756310  3.777267  3.798224   \n",
       "3  2017-01-03    ABT  33.307190  50.624336  3.504776  3.523770  3.542764   \n",
       "4  2017-01-03   ACGL  27.224224  59.555791  3.323679  3.345575  3.367472   \n",
       "\n",
       "   sharpe_ratio  \n",
       "0      0.548844  \n",
       "1      0.836831  \n",
       "2      0.661857  \n",
       "3      0.568612  \n",
       "4      0.645114  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['date','ticker','close','rsi','bb_low', 'bb_mid', 'bb_high', 'sharpe_ratio']\n",
    "df = pd.read_csv(\"data/price_data.csv\", usecols=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5725e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>close</th>\n",
       "      <th>rsi</th>\n",
       "      <th>bb_low</th>\n",
       "      <th>bb_mid</th>\n",
       "      <th>bb_high</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>43.559391</td>\n",
       "      <td>55.906011</td>\n",
       "      <td>3.757332</td>\n",
       "      <td>3.781197</td>\n",
       "      <td>3.805061</td>\n",
       "      <td>0.548844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>26.827240</td>\n",
       "      <td>58.487161</td>\n",
       "      <td>3.274114</td>\n",
       "      <td>3.315296</td>\n",
       "      <td>3.356479</td>\n",
       "      <td>0.836831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>43.078159</td>\n",
       "      <td>53.851836</td>\n",
       "      <td>3.756310</td>\n",
       "      <td>3.777267</td>\n",
       "      <td>3.798224</td>\n",
       "      <td>0.661857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>ABT</td>\n",
       "      <td>33.307190</td>\n",
       "      <td>50.624336</td>\n",
       "      <td>3.504776</td>\n",
       "      <td>3.523770</td>\n",
       "      <td>3.542764</td>\n",
       "      <td>0.568612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>ACGL</td>\n",
       "      <td>27.224224</td>\n",
       "      <td>59.555791</td>\n",
       "      <td>3.323679</td>\n",
       "      <td>3.345575</td>\n",
       "      <td>3.367472</td>\n",
       "      <td>0.645114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker      close        rsi    bb_low    bb_mid   bb_high  \\\n",
       "0  2017-01-03      A  43.559391  55.906011  3.757332  3.781197  3.805061   \n",
       "1  2017-01-03   AAPL  26.827240  58.487161  3.274114  3.315296  3.356479   \n",
       "2  2017-01-03   ABBV  43.078159  53.851836  3.756310  3.777267  3.798224   \n",
       "3  2017-01-03    ABT  33.307190  50.624336  3.504776  3.523770  3.542764   \n",
       "4  2017-01-03   ACGL  27.224224  59.555791  3.323679  3.345575  3.367472   \n",
       "\n",
       "   sharpe_ratio  \n",
       "0      0.548844  \n",
       "1      0.836831  \n",
       "2      0.661857  \n",
       "3      0.568612  \n",
       "4      0.645114  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoke_test = False\n",
    "if smoke_test:\n",
    "    df = df[df[\"ticker\"] == \"AAPL\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1d0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df[df.date <= end_date], df[df.date > end_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7b65c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape after feature engineering: (1018847, 9)\n",
      "Feature columns: 5\n",
      "0:\tlearn: 289.4240511\ttotal: 559ms\tremaining: 13m 57s\n",
      "200:\tlearn: 243.5079717\ttotal: 1m 24s\tremaining: 9m 8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 267\u001b[0m\n\u001b[0;32m    264\u001b[0m stock_model \u001b[38;5;241m=\u001b[39m StockPredictionModel()\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# Train the model (assuming you have train_df already split by date)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m model, feature_importance \u001b[38;5;241m=\u001b[39m \u001b[43mstock_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnext_day_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'next_day_price'\u001b[39;49;00m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdepth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ml2_leaf_reg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_seed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mverbose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Make predictions on test data\u001b[39;00m\n\u001b[0;32m    281\u001b[0m predictions \u001b[38;5;241m=\u001b[39m stock_model\u001b[38;5;241m.\u001b[39mpredict(test, target_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_day_price\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 135\u001b[0m, in \u001b[0;36mStockPredictionModel.train_model\u001b[1;34m(self, train_df, target_type, model_params)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Initialize and train model\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m CatBoostRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Feature importance\u001b[39;00m\n\u001b[0;32m    138\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_columns \u001b[38;5;241m+\u001b[39m categorical_features,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_feature_importance()\n\u001b[0;32m    141\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\llm\\lib\\site-packages\\catboost\\core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\llm\\lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\feder\\anaconda3\\envs\\llm\\lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class StockPredictionModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.feature_columns = None\n",
    "        self.scaler = None\n",
    "        \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"\n",
    "        Prepare features for the model while avoiding data leakage\n",
    "        \"\"\"\n",
    "        # Make a copy to avoid modifying original data\n",
    "        data = df.copy()\n",
    "        \n",
    "        # Convert date to datetime if it's not already\n",
    "        if not pd.api.types.is_datetime64_any_dtype(data['date']):\n",
    "            data['date'] = pd.to_datetime(data['date'])\n",
    "        \n",
    "        # Sort by ticker and date to ensure proper time series order\n",
    "        data = data.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "        \n",
    "        # Create lagged features to avoid data leakage\n",
    "        # We'll create features based on past values only\n",
    "        feature_cols = []\n",
    "        \n",
    "        # Group by ticker to create lagged features per stock\n",
    "        for ticker in data['ticker'].unique():\n",
    "            ticker_mask = data['ticker'] == ticker\n",
    "            ticker_data = data[ticker_mask].copy()\n",
    "            \n",
    "            # Create lagged features (using past values only)\n",
    "            for lag in [1, 2, 3, 5, 10]:\n",
    "                ticker_data[f'close_lag_{lag}'] = ticker_data['close'].shift(lag)\n",
    "                ticker_data[f'rsi_lag_{lag}'] = ticker_data['rsi'].shift(lag)\n",
    "                \n",
    "            # Create rolling statistics (using past values only)\n",
    "            for window in [5, 10, 20]:\n",
    "                ticker_data[f'close_ma_{window}'] = ticker_data['close'].shift(1).rolling(window=window).mean()\n",
    "                ticker_data[f'close_std_{window}'] = ticker_data['close'].shift(1).rolling(window=window).std()\n",
    "                ticker_data[f'rsi_ma_{window}'] = ticker_data['rsi'].shift(1).rolling(window=window).mean()\n",
    "            \n",
    "            # Price change features (using lagged prices)\n",
    "            ticker_data['price_change_1d'] = (ticker_data['close'].shift(1) - ticker_data['close'].shift(2)) / ticker_data['close'].shift(2)\n",
    "            ticker_data['price_change_5d'] = (ticker_data['close'].shift(1) - ticker_data['close'].shift(6)) / ticker_data['close'].shift(6)\n",
    "            \n",
    "            # Bollinger Band position (using lagged values)\n",
    "            ticker_data['bb_position'] = (ticker_data['close'].shift(1) - ticker_data['bb_low'].shift(1)) / (ticker_data['bb_high'].shift(1) - ticker_data['bb_low'].shift(1))\n",
    "            \n",
    "            # RSI momentum\n",
    "            ticker_data['rsi_momentum'] = ticker_data['rsi'].shift(1) - ticker_data['rsi'].shift(2)\n",
    "            \n",
    "            # Update the main dataframe\n",
    "            data.loc[ticker_mask] = ticker_data\n",
    "        \n",
    "        # Define feature columns (excluding date, ticker, and target)\n",
    "        self.feature_columns = [col for col in data.columns if col not in ['date', 'ticker', 'close']]\n",
    "        \n",
    "        # Add categorical features\n",
    "        categorical_features = ['ticker']\n",
    "        \n",
    "        return data, categorical_features\n",
    "    \n",
    "    def create_target(self, df, target_type='next_day_return'):\n",
    "        \"\"\"\n",
    "        Create target variable for prediction\n",
    "        \"\"\"\n",
    "        data = df.copy()\n",
    "        data = data.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "        \n",
    "        if target_type == 'next_day_return':\n",
    "            # Predict next day return\n",
    "            for ticker in data['ticker'].unique():\n",
    "                ticker_mask = data['ticker'] == ticker\n",
    "                ticker_data = data[ticker_mask].copy()\n",
    "                ticker_data['target'] = (ticker_data['close'].shift(-1) - ticker_data['close']) / ticker_data['close']\n",
    "                data.loc[ticker_mask, 'target'] = ticker_data['target']\n",
    "        \n",
    "        elif target_type == 'next_day_price':\n",
    "            # Predict next day price\n",
    "            for ticker in data['ticker'].unique():\n",
    "                ticker_mask = data['ticker'] == ticker\n",
    "                ticker_data = data[ticker_mask].copy()\n",
    "                ticker_data['target'] = ticker_data['close'].shift(-1)\n",
    "                data.loc[ticker_mask, 'target'] = ticker_data['target']\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def train_model(self, train_df, target_type='next_day_return', model_params=None):\n",
    "        \"\"\"\n",
    "        Train the CatBoost model\n",
    "        \"\"\"\n",
    "        # Prepare features and target\n",
    "        train_data, categorical_features = self.prepare_features(train_df)\n",
    "        train_data = self.create_target(train_data, target_type)\n",
    "        \n",
    "        # Remove rows with NaN values (due to lagged features and target creation)\n",
    "        train_data = train_data.dropna()\n",
    "        \n",
    "        print(f\"Training data shape after feature engineering: {train_data.shape}\")\n",
    "        print(f\"Feature columns: {len(self.feature_columns)}\")\n",
    "        \n",
    "        # Prepare training data\n",
    "        X_train = train_data[self.feature_columns + ['ticker']]\n",
    "        y_train = train_data['target']\n",
    "        \n",
    "        # Default CatBoost parameters optimized for financial data\n",
    "        if model_params is None:\n",
    "            model_params = {\n",
    "                'iterations': 1000,\n",
    "                'learning_rate': 0.1,\n",
    "                'depth': 6,\n",
    "                'l2_leaf_reg': 3,\n",
    "                'random_seed': 42,\n",
    "                'verbose': 100,\n",
    "                'early_stopping_rounds': 50,\n",
    "                'use_best_model': True,\n",
    "                'eval_metric': 'RMSE'\n",
    "            }\n",
    "        \n",
    "        # Create CatBoost pools\n",
    "        train_pool = Pool(\n",
    "            data=X_train,\n",
    "            label=y_train,\n",
    "            cat_features=categorical_features\n",
    "        )\n",
    "        \n",
    "        # Initialize and train model\n",
    "        self.model = CatBoostRegressor(**model_params)\n",
    "        self.model.fit(train_pool)\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': self.feature_columns + categorical_features,\n",
    "            'importance': self.model.get_feature_importance()\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 10 most important features:\")\n",
    "        print(feature_importance.head(10))\n",
    "        \n",
    "        return self.model, feature_importance\n",
    "    \n",
    "    def predict(self, test_df, target_type='next_day_return'):\n",
    "        \"\"\"\n",
    "        Make predictions on test data\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
    "        \n",
    "        # Prepare features (using the same feature engineering as training)\n",
    "        test_data, _ = self.prepare_features(test_df)\n",
    "        test_data = self.create_target(test_data, target_type)  # We need this to align data structure\n",
    "        \n",
    "        # Remove rows with NaN values\n",
    "        test_data_clean = test_data.dropna()\n",
    "        \n",
    "        print(f\"Test data shape after feature engineering: {test_data_clean.shape}\")\n",
    "        \n",
    "        # Prepare test features\n",
    "        X_test = test_data_clean[self.feature_columns + ['ticker']]\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(X_test)\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = test_data_clean[['date', 'ticker', 'close', 'target']].copy()\n",
    "        results['predicted'] = predictions\n",
    "        results['actual_target'] = results['target']\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_model(self, results_df):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \"\"\"\n",
    "        # Remove any remaining NaN values\n",
    "        eval_data = results_df.dropna()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(eval_data['actual_target'], eval_data['predicted'])\n",
    "        mae = mean_absolute_error(eval_data['actual_target'], eval_data['predicted'])\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(eval_data['actual_target'], eval_data['predicted'])\n",
    "        \n",
    "        print(\"Model Performance Metrics:\")\n",
    "        print(f\"RMSE: {rmse:.6f}\")\n",
    "        print(f\"MAE: {mae:.6f}\")\n",
    "        print(f\"R²: {r2:.6f}\")\n",
    "        \n",
    "        # Directional accuracy (for return prediction)\n",
    "        if 'actual_target' in eval_data.columns:\n",
    "            correct_direction = ((eval_data['actual_target'] > 0) == (eval_data['predicted'] > 0)).mean()\n",
    "            print(f\"Directional Accuracy: {correct_direction:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2,\n",
    "            'directional_accuracy': correct_direction if 'actual_target' in eval_data.columns else None\n",
    "        }\n",
    "    \n",
    "    def plot_results(self, results_df, ticker=None):\n",
    "        \"\"\"\n",
    "        Plot prediction results\n",
    "        \"\"\"\n",
    "        plot_data = results_df.copy()\n",
    "        \n",
    "        if ticker:\n",
    "            plot_data = plot_data[plot_data['ticker'] == ticker]\n",
    "            title_suffix = f\" - {ticker}\"\n",
    "        else:\n",
    "            title_suffix = \" - All Tickers\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Actual vs Predicted scatter plot\n",
    "        axes[0, 0].scatter(plot_data['actual_target'], plot_data['predicted'], alpha=0.6)\n",
    "        axes[0, 0].plot([plot_data['actual_target'].min(), plot_data['actual_target'].max()], \n",
    "                       [plot_data['actual_target'].min(), plot_data['actual_target'].max()], 'r--')\n",
    "        axes[0, 0].set_xlabel('Actual')\n",
    "        axes[0, 0].set_ylabel('Predicted')\n",
    "        axes[0, 0].set_title(f'Actual vs Predicted{title_suffix}')\n",
    "        \n",
    "        # Prediction errors\n",
    "        errors = plot_data['predicted'] - plot_data['actual_target']\n",
    "        axes[0, 1].hist(errors, bins=50, alpha=0.7)\n",
    "        axes[0, 1].set_xlabel('Prediction Error')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title(f'Prediction Error Distribution{title_suffix}')\n",
    "        \n",
    "        # Time series of predictions (if ticker specified)\n",
    "        if ticker and len(plot_data) > 1:\n",
    "            plot_data_sorted = plot_data.sort_values('date')\n",
    "            axes[1, 0].plot(plot_data_sorted['date'], plot_data_sorted['actual_target'], label='Actual', alpha=0.7)\n",
    "            axes[1, 0].plot(plot_data_sorted['date'], plot_data_sorted['predicted'], label='Predicted', alpha=0.7)\n",
    "            axes[1, 0].set_xlabel('Date')\n",
    "            axes[1, 0].set_ylabel('Target Value')\n",
    "            axes[1, 0].set_title(f'Time Series Comparison{title_suffix}')\n",
    "            axes[1, 0].legend()\n",
    "            axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'Time series plot\\navailable for\\nsingle ticker only', \n",
    "                           ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        \n",
    "        # Residuals vs Predicted\n",
    "        residuals = plot_data['actual_target'] - plot_data['predicted']\n",
    "        axes[1, 1].scatter(plot_data['predicted'], residuals, alpha=0.6)\n",
    "        axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "        axes[1, 1].set_xlabel('Predicted')\n",
    "        axes[1, 1].set_ylabel('Residuals')\n",
    "        axes[1, 1].set_title(f'Residuals vs Predicted{title_suffix}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Initialize the model\n",
    "stock_model = StockPredictionModel()\n",
    "\n",
    "# Train the model (assuming you have train_df already split by date)\n",
    "model, feature_importance = stock_model.train_model(\n",
    "    train, \n",
    "    target_type='next_day_price',  # or 'next_day_price'\n",
    "    model_params={\n",
    "        'iterations': 1500,\n",
    "        'learning_rate': 0.001,\n",
    "        'depth': 8,\n",
    "        'l2_leaf_reg': 5,\n",
    "        'random_seed': 42,\n",
    "        'verbose': 200\n",
    "    }\n",
    ")\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = stock_model.predict(test, target_type='next_day_price')\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = stock_model.evaluate_model(predictions)\n",
    "\n",
    "# Plot results for a specific ticker or all tickers\n",
    "stock_model.plot_results(predictions, ticker='AAPL')  # For specific ticker\n",
    "stock_model.plot_results(predictions)  # For all tickers\n",
    "\n",
    "\n",
    "# Load the model later\n",
    "# loaded_model = CatBoostRegressor()\n",
    "# loaded_model.load_model('stock_prediction_model.cbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
